{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab763c49-f3f6-475c-86ba-a9636f86bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the permit data\n",
    "permits_df = pd.read_csv('nyc_permits_raw.csv', low_memory=False)\n",
    "\n",
    "# Convert date to datetime\n",
    "permits_df['pre__filing_date'] = pd.to_datetime(permits_df['pre__filing_date'], errors='coerce')\n",
    "\n",
    "# Extract year\n",
    "permits_df['year'] = permits_df['pre__filing_date'].dt.year\n",
    "\n",
    "# Make sure geoid is clean (string, no nulls)\n",
    "permits_df['gis_census_tract'] = permits_df['gis_census_tract'].astype(str).str.strip()\n",
    "\n",
    "# Filter out any rows without valid year or tract\n",
    "permits_df = permits_df[\n",
    "    (permits_df['year'].notna()) & \n",
    "    (permits_df['gis_census_tract'] != '') & \n",
    "    (permits_df['gis_census_tract'] != 'nan')\n",
    "]\n",
    "\n",
    "print(f\"After cleaning: {len(permits_df)} records\")\n",
    "\n",
    "# Aggregate by census tract and year\n",
    "permits_summary = permits_df.groupby(['gis_census_tract', 'borough', 'year', 'job_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Flatten and rename\n",
    "permits_summary = permits_summary.reset_index()\n",
    "permits_summary.columns.name = None\n",
    "\n",
    "# Calculate totals and specific counts\n",
    "permits_agg = permits_summary.copy()\n",
    "permits_agg['total_permits'] = permits_agg[['A1', 'A2', 'A3', 'NB']].sum(axis=1)\n",
    "permits_agg = permits_agg.rename(columns={\n",
    "    'A1': 'major_alterations',\n",
    "    'A2': 'minor_alterations_a2',\n",
    "    'A3': 'minor_alterations_a3',\n",
    "    'NB': 'new_buildings',\n",
    "    'gis_census_tract': 'geoid'\n",
    "})\n",
    "\n",
    "# Combine A2 and A3 into one minor alterations column\n",
    "permits_agg['minor_alterations'] = permits_agg['minor_alterations_a2'] + permits_agg['minor_alterations_a3']\n",
    "permits_agg = permits_agg.drop(columns=['minor_alterations_a2', 'minor_alterations_a3'])\n",
    "\n",
    "print(f\"\\nAggregated permit data shape: {permits_agg.shape}\")\n",
    "print(f\"\\nSample aggregated data:\")\n",
    "print(permits_agg.head(10))\n",
    "\n",
    "# Save aggregated data\n",
    "permits_agg.to_csv('nyc_permits_aggregated.csv', index=False)\n",
    "print(\"\\nAggregated permit data saved to nyc_permits_aggregated.csv\")\n",
    "\n",
    "# Show summary stats\n",
    "print(f\"\\nYears covered: {permits_agg['year'].min()} to {permits_agg['year'].max()}\")\n",
    "print(f\"\\nTotal permits per year:\")\n",
    "yearly_totals = permits_agg.groupby('year')['total_permits'].sum().sort_index()\n",
    "print(yearly_totals)\n",
    "\n",
    "print(f\"\\nPermits by borough (all years):\")\n",
    "borough_totals = permits_agg.groupby('borough')['total_permits'].sum().sort_values(ascending=False)\n",
    "print(borough_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4400646-cad0-450f-b4cc-11f082a674a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets to verify they're ready\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "permits_df = pd.read_csv('nyc_permits_aggregated.csv')\n",
    "\n",
    "print(\"=== ACS Data ===\")\n",
    "print(f\"Shape: {acs_df.shape}\")\n",
    "print(f\"Years: {sorted(acs_df['year'].unique())}\")\n",
    "print(f\"Columns: {acs_df.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(acs_df.head(3))\n",
    "\n",
    "print(\"\\n=== Permits Data ===\")\n",
    "print(f\"Shape: {permits_df.shape}\")\n",
    "print(f\"Years: {sorted(permits_df['year'].unique())}\")\n",
    "print(f\"Columns: {permits_df.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(permits_df.head(3))\n",
    "\n",
    "# Check if geoids match between datasets\n",
    "acs_tracts = set(acs_df['geoid'].unique())\n",
    "permit_tracts = set(permits_df['geoid'].unique())\n",
    "\n",
    "print(f\"\\n=== Data Compatibility ===\")\n",
    "print(f\"Unique tracts in ACS: {len(acs_tracts)}\")\n",
    "print(f\"Unique tracts in permits: {len(permit_tracts)}\")\n",
    "print(f\"Tracts in both datasets: {len(acs_tracts & permit_tracts)}\")\n",
    "print(f\"Tracts only in ACS: {len(acs_tracts - permit_tracts)}\")\n",
    "print(f\"Tracts only in permits: {len(permit_tracts - acs_tracts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21200309-c45a-4384-87aa-2b5b448cdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "permits_df = pd.read_csv('nyc_permits_aggregated.csv')\n",
    "\n",
    "# Look at sample geoids from each dataset\n",
    "print(\"=== ACS geoid samples ===\")\n",
    "print(acs_df['geoid'].head(20).tolist())\n",
    "\n",
    "print(\"\\n=== Permits geoid samples ===\")\n",
    "print(permits_df['geoid'].head(20).tolist())\n",
    "\n",
    "# Check geoid characteristics\n",
    "print(\"\\n=== ACS geoid characteristics ===\")\n",
    "print(f\"Data type: {acs_df['geoid'].dtype}\")\n",
    "print(f\"Min length: {acs_df['geoid'].astype(str).str.len().min()}\")\n",
    "print(f\"Max length: {acs_df['geoid'].astype(str).str.len().max()}\")\n",
    "print(f\"Sample unique values: {acs_df['geoid'].unique()[:10]}\")\n",
    "\n",
    "print(\"\\n=== Permits geoid characteristics ===\")\n",
    "print(f\"Data type: {permits_df['geoid'].dtype}\")\n",
    "print(f\"Min length: {permits_df['geoid'].astype(str).str.len().min()}\")\n",
    "print(f\"Max length: {permits_df['geoid'].astype(str).str.len().max()}\")\n",
    "print(f\"Sample unique values: {permits_df['geoid'].unique()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f71ff-7ea9-4b1f-95f3-40d0600872c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "permits_df = pd.read_csv('nyc_permits_aggregated.csv')\n",
    "\n",
    "# Standardize permits geoid to match ACS format\n",
    "# Pad with leading zeros to make all geoids the same length\n",
    "# Most NYC census tracts are 4-6 digits, let's check the max length needed\n",
    "max_len = acs_df['geoid'].astype(str).str.len().max()\n",
    "print(f\"Max geoid length in ACS: {max_len}\")\n",
    "\n",
    "# Pad permits geoid to match\n",
    "permits_df['geoid'] = permits_df['geoid'].astype(str).str.zfill(max_len)\n",
    "\n",
    "# Also ensure ACS geoid is string and padded consistently\n",
    "acs_df['geoid'] = acs_df['geoid'].astype(str).str.zfill(max_len)\n",
    "\n",
    "# Save the cleaned versions\n",
    "acs_df.to_csv('nyc_acs_data_2009_2023.csv', index=False)\n",
    "permits_df.to_csv('nyc_permits_aggregated.csv', index=False)\n",
    "\n",
    "# Check overlap again\n",
    "acs_tracts = set(acs_df['geoid'].unique())\n",
    "permit_tracts = set(permits_df['geoid'].unique())\n",
    "\n",
    "print(f\"\\n=== After standardization ===\")\n",
    "print(f\"Unique tracts in ACS: {len(acs_tracts)}\")\n",
    "print(f\"Unique tracts in permits: {len(permit_tracts)}\")\n",
    "print(f\"Tracts in both datasets: {len(acs_tracts & permit_tracts)}\")\n",
    "print(f\"Tracts only in ACS: {len(acs_tracts - permit_tracts)}\")\n",
    "print(f\"Tracts only in permits: {len(permit_tracts - acs_tracts)}\")\n",
    "\n",
    "print(\"\\n=== Sample standardized geoids ===\")\n",
    "print(\"ACS:\", acs_df['geoid'].head(10).tolist())\n",
    "print(\"Permits:\", permits_df['geoid'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4def9-afbf-44df-96f0-d8f1a4452c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "permits_df = pd.read_csv('nyc_permits_aggregated.csv')\n",
    "\n",
    "# Convert both to string for comparison\n",
    "acs_df['geoid'] = acs_df['geoid'].astype(str)\n",
    "permits_df['geoid'] = permits_df['geoid'].astype(str)\n",
    "\n",
    "# Find tracts that don't overlap\n",
    "acs_tracts = set(acs_df['geoid'].unique())\n",
    "permit_tracts = set(permits_df['geoid'].unique())\n",
    "\n",
    "only_in_acs = sorted(list(acs_tracts - permit_tracts))\n",
    "only_in_permits = sorted(list(permit_tracts - acs_tracts))\n",
    "\n",
    "print(\"=== Tracts only in ACS (first 30) ===\")\n",
    "print(only_in_acs[:30])\n",
    "\n",
    "print(\"\\n=== Tracts only in permits (first 30) ===\")\n",
    "print(only_in_permits[:30])\n",
    "\n",
    "# Check permits with '1' in geoid - look for patterns\n",
    "print(\"\\n=== Permits geoids starting with 0 ===\")\n",
    "print(sorted([g for g in permit_tracts if g.startswith('0')])[:20])\n",
    "\n",
    "print(\"\\n=== ACS geoids starting with 0 ===\")\n",
    "print(sorted([g for g in acs_tracts if g.startswith('0')])[:20])\n",
    "\n",
    "# Check the raw permits data before aggregation to see what gis_census_tract looks like\n",
    "raw_permits = pd.read_csv('nyc_permits_raw.csv', low_memory=False)\n",
    "print(\"\\n=== Raw permits gis_census_tract samples ===\")\n",
    "print(raw_permits['gis_census_tract'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40469e-5078-4d8f-8809-7ab10a496267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "permits_df = pd.read_csv('nyc_permits_aggregated.csv')\n",
    "\n",
    "# Convert to string\n",
    "acs_df['geoid'] = acs_df['geoid'].astype(str)\n",
    "permits_df['geoid'] = permits_df['geoid'].astype(str)\n",
    "\n",
    "# Try matching: does the permit tract ID appear at the END of the ACS tract?\n",
    "# For example, permit \"102\" might match ACS tract \"100102\" or \"000102\"\n",
    "\n",
    "# Test with a specific example\n",
    "test_permit_tract = '102'\n",
    "test_acs_matches = [t for t in acs_df['geoid'].unique() if t.endswith(test_permit_tract)]\n",
    "print(f\"Permit tract '{test_permit_tract}' potentially matches ACS tracts: {test_acs_matches}\")\n",
    "\n",
    "# Another test\n",
    "test_permit_tract2 = '7'  \n",
    "test_acs_matches2 = [t for t in acs_df['geoid'].unique() if t.endswith(test_permit_tract2)]\n",
    "print(f\"Permit tract '{test_permit_tract2}' potentially matches ACS tracts: {test_acs_matches2}\")\n",
    "\n",
    "# Check if this pattern works broadly\n",
    "# For permits tracts that are 3 digits, check if they match the last 3 digits of ACS\n",
    "sample_permits_3dig = [g for g in permits_df['geoid'].unique() if len(g) == 3][:10]\n",
    "print(f\"\\nSample 3-digit permit tracts: {sample_permits_3dig}\")\n",
    "for p in sample_permits_3dig[:3]:\n",
    "    matches = [t for t in acs_df['geoid'].unique() if t.endswith(p)]\n",
    "    print(f\"  Permit '{p}' → ACS matches: {matches[:5] if len(matches) > 5 else matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe771a1-7678-4326-9de7-1be010efecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load permits\n",
    "raw_permits = pd.read_csv('nyc_permits_raw.csv', low_memory=False)\n",
    "\n",
    "# Convert coordinates to numeric\n",
    "raw_permits['gis_latitude'] = pd.to_numeric(raw_permits['gis_latitude'], errors='coerce')\n",
    "raw_permits['gis_longitude'] = pd.to_numeric(raw_permits['gis_longitude'], errors='coerce')\n",
    "\n",
    "# Filter to records with valid coordinates\n",
    "permits_with_coords = raw_permits[\n",
    "    raw_permits['gis_latitude'].notna() & \n",
    "    raw_permits['gis_longitude'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Permits with coordinates: {len(permits_with_coords)} out of {len(raw_permits)}\")\n",
    "print(f\"Percentage: {len(permits_with_coords)/len(raw_permits)*100:.1f}%\")\n",
    "\n",
    "# Check coordinate ranges (NYC should be roughly 40.5-40.9 lat, -74.3 to -73.7 lon)\n",
    "print(f\"\\nLatitude range: {permits_with_coords['gis_latitude'].min()} to {permits_with_coords['gis_latitude'].max()}\")\n",
    "print(f\"Longitude range: {permits_with_coords['gis_longitude'].min()} to {permits_with_coords['gis_longitude'].max()}\")\n",
    "\n",
    "# Check for suspicious patterns (all the same value, too many duplicates)\n",
    "print(f\"\\nUnique latitude values: {permits_with_coords['gis_latitude'].nunique()}\")\n",
    "print(f\"Unique longitude values: {permits_with_coords['gis_longitude'].nunique()}\")\n",
    "\n",
    "# Most common coordinates (if many permits have identical coords, it's suspicious)\n",
    "print(\"\\nMost common coordinate pairs:\")\n",
    "coord_counts = permits_with_coords.groupby(['gis_latitude', 'gis_longitude']).size().sort_values(ascending=False)\n",
    "print(coord_counts.head(10))\n",
    "\n",
    "# Plot to visualize distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Scatter plot of all coordinates\n",
    "sample = permits_with_coords.sample(min(10000, len(permits_with_coords)))  # Sample for speed\n",
    "ax1.scatter(sample['gis_longitude'], sample['gis_latitude'], alpha=0.1, s=1)\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.set_title('Permit Locations (sample)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of coordinates\n",
    "ax2.hist2d(permits_with_coords['gis_longitude'], permits_with_coords['gis_latitude'], \n",
    "           bins=100, cmap='YlOrRd')\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "ax2.set_title('Permit Density Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('permit_coordinates_check.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\nSaved visualization to permit_coordinates_check.png\")\n",
    "\n",
    "# Check by borough\n",
    "print(\"\\nCoordinates by borough:\")\n",
    "for borough in permits_with_coords['borough'].unique():\n",
    "    borough_data = permits_with_coords[permits_with_coords['borough'] == borough]\n",
    "    print(f\"\\n{borough}:\")\n",
    "    print(f\"  Count: {len(borough_data)}\")\n",
    "    print(f\"  Lat range: {borough_data['gis_latitude'].min():.4f} to {borough_data['gis_latitude'].max():.4f}\")\n",
    "    print(f\"  Lon range: {borough_data['gis_longitude'].min():.4f} to {borough_data['gis_longitude'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dae45-09c2-46b5-892b-472b447f98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load permits with coordinates\n",
    "raw_permits = pd.read_csv('nyc_permits_raw.csv', low_memory=False)\n",
    "\n",
    "# Keep only the columns we need and filter to our date range\n",
    "raw_permits['pre__filing_date'] = pd.to_datetime(raw_permits['pre__filing_date'], errors='coerce')\n",
    "raw_permits = raw_permits[\n",
    "    (raw_permits['pre__filing_date'] >= '2009-01-01') & \n",
    "    (raw_permits['pre__filing_date'] <= '2023-12-31') &\n",
    "    (raw_permits['job_type'].isin(['A1', 'A2', 'A3', 'NB'])) &\n",
    "    (raw_permits['job_status'].isin(['R', 'D', 'X', 'C']))\n",
    "]\n",
    "\n",
    "raw_permits['gis_latitude'] = pd.to_numeric(raw_permits['gis_latitude'], errors='coerce')\n",
    "raw_permits['gis_longitude'] = pd.to_numeric(raw_permits['gis_longitude'], errors='coerce')\n",
    "\n",
    "print(f\"Filtered permits: {len(raw_permits)}\")\n",
    "\n",
    "# Create Point geometries\n",
    "geometry = [Point(xy) for xy in zip(raw_permits['gis_longitude'], raw_permits['gis_latitude'])]\n",
    "permits_gdf = gpd.GeoDataFrame(\n",
    "    raw_permits[['pre__filing_date', 'job_type', 'borough']],\n",
    "    geometry=geometry,\n",
    "    crs='EPSG:4326'  # WGS84 coordinate system\n",
    ")\n",
    "\n",
    "print(f\"Created GeoDataFrame with {len(permits_gdf)} permits\")\n",
    "\n",
    "# Download census tract boundaries\n",
    "# We'll use the Census Bureau's TIGER/Line shapefiles via the web\n",
    "# For NYC, we need state=36, counties=005,047,061,081,085\n",
    "print(\"\\nDownloading census tract boundaries...\")\n",
    "\n",
    "# Using Census TIGER/Line data for 2020 (most recent standard boundaries)\n",
    "url = \"https://www2.census.gov/geo/tiger/TIGER2020/TRACT/tl_2020_36_tract.zip\"\n",
    "\n",
    "try:\n",
    "    tracts_gdf = gpd.read_file(url)\n",
    "    print(f\"Downloaded {len(tracts_gdf)} census tracts for NY State\")\n",
    "    \n",
    "    # Filter to NYC counties (005=Bronx, 047=Kings, 061=New York, 081=Queens, 085=Richmond)\n",
    "    nyc_counties = ['005', '047', '061', '081', '085']\n",
    "    tracts_gdf = tracts_gdf[tracts_gdf['COUNTYFP'].isin(nyc_counties)]\n",
    "    \n",
    "    print(f\"Filtered to {len(tracts_gdf)} NYC census tracts\")\n",
    "    \n",
    "    # The GEOID in this data is 11 digits: STATEFPCOUNTYFPTRACTCE\n",
    "    # We want just the TRACTCE (last 6 digits) to match our ACS data\n",
    "    tracts_gdf['geoid'] = tracts_gdf['TRACTCE']\n",
    "    \n",
    "    # Save the tracts for reference\n",
    "    tracts_gdf.to_file('nyc_census_tracts.geojson', driver='GeoJSON')\n",
    "    print(\"Saved census tract boundaries to nyc_census_tracts.geojson\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error downloading tracts: {e}\")\n",
    "    print(\"Will try alternative source...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838537f-99d7-4df4-b71b-81ba6f9d27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load the permits\n",
    "raw_permits = pd.read_csv('nyc_permits_raw.csv', low_memory=False)\n",
    "\n",
    "# Filter and prepare\n",
    "raw_permits['pre__filing_date'] = pd.to_datetime(raw_permits['pre__filing_date'], errors='coerce')\n",
    "raw_permits['year'] = raw_permits['pre__filing_date'].dt.year\n",
    "\n",
    "raw_permits = raw_permits[\n",
    "    (raw_permits['year'] >= 2009) & \n",
    "    (raw_permits['year'] <= 2023) &\n",
    "    (raw_permits['job_type'].isin(['A1', 'A2', 'A3', 'NB'])) &\n",
    "    (raw_permits['job_status'].isin(['R', 'D', 'X', 'C']))\n",
    "]\n",
    "\n",
    "raw_permits['gis_latitude'] = pd.to_numeric(raw_permits['gis_latitude'], errors='coerce')\n",
    "raw_permits['gis_longitude'] = pd.to_numeric(raw_permits['gis_longitude'], errors='coerce')\n",
    "\n",
    "print(f\"Filtered permits: {len(raw_permits)}\")\n",
    "\n",
    "# Create GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(raw_permits['gis_longitude'], raw_permits['gis_latitude'])]\n",
    "permits_gdf = gpd.GeoDataFrame(\n",
    "    raw_permits[['year', 'job_type', 'borough']],\n",
    "    geometry=geometry,\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Load census tracts\n",
    "tracts_gdf = gpd.read_file('nyc_census_tracts.geojson')\n",
    "print(f\"Loaded {len(tracts_gdf)} census tracts\")\n",
    "\n",
    "# Ensure same CRS\n",
    "tracts_gdf = tracts_gdf.to_crs('EPSG:4326')\n",
    "\n",
    "# Spatial join - find which tract each permit falls in\n",
    "print(\"\\nPerforming spatial join... this may take a few minutes\")\n",
    "permits_with_tracts = gpd.sjoin(permits_gdf, tracts_gdf[['geoid', 'geometry']], how='left', predicate='within')\n",
    "\n",
    "print(f\"Spatial join complete\")\n",
    "print(f\"Permits with matched tracts: {permits_with_tracts['geoid'].notna().sum()}\")\n",
    "print(f\"Permits without matched tracts: {permits_with_tracts['geoid'].isna().sum()}\")\n",
    "\n",
    "# Aggregate by census tract and year\n",
    "permits_agg = permits_with_tracts.groupby(['geoid', 'year']).agg({\n",
    "    'job_type': 'count'  # Total permits\n",
    "}).rename(columns={'job_type': 'total_permits'})\n",
    "\n",
    "# Break down by job type\n",
    "permits_agg['major_alterations'] = permits_with_tracts[permits_with_tracts['job_type'] == 'A1'].groupby(['geoid', 'year']).size()\n",
    "permits_agg['minor_alterations'] = permits_with_tracts[permits_with_tracts['job_type'].isin(['A2', 'A3'])].groupby(['geoid', 'year']).size()\n",
    "permits_agg['new_buildings'] = permits_with_tracts[permits_with_tracts['job_type'] == 'NB'].groupby(['geoid', 'year']).size()\n",
    "\n",
    "# Fill NaNs with 0\n",
    "permits_agg = permits_agg.fillna(0).astype(int)\n",
    "permits_agg = permits_agg.reset_index()\n",
    "\n",
    "# Pad geoid to 6 digits to match ACS\n",
    "permits_agg['geoid'] = permits_agg['geoid'].astype(str).str.zfill(6)\n",
    "\n",
    "print(f\"\\nAggregated permit data shape: {permits_agg.shape}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(permits_agg.head(10))\n",
    "\n",
    "# Save\n",
    "permits_agg.to_csv('nyc_permits_geocoded.csv', index=False)\n",
    "print(\"\\nSaved geocoded permit data to nyc_permits_geocoded.csv\")\n",
    "\n",
    "# Check overlap with ACS data\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "acs_df['geoid'] = acs_df['geoid'].astype(str).str.zfill(6)\n",
    "\n",
    "acs_tracts = set(acs_df['geoid'].unique())\n",
    "permit_tracts = set(permits_agg['geoid'].unique())\n",
    "\n",
    "print(f\"\\n=== Overlap Check ===\")\n",
    "print(f\"Unique tracts in ACS: {len(acs_tracts)}\")\n",
    "print(f\"Unique tracts in permits: {len(permit_tracts)}\")\n",
    "print(f\"Tracts in both datasets: {len(acs_tracts & permit_tracts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad6017-2cd9-483a-a712-1ff86deb11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import getpass\n",
    "\n",
    "# Use your Mac username instead of 'postgres'\n",
    "username = getpass.getuser()  # Gets your current username\n",
    "\n",
    "DB_PARAMS = {\n",
    "    'dbname': 'nyc_gentrification',\n",
    "    'user': username,  # Your Mac username\n",
    "    'password': '',  # Homebrew postgres usually has no password\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# First, create the database (connect to default db first)\n",
    "try:\n",
    "    conn = psycopg2.connect(dbname='postgres', user=username, \n",
    "                           password='', host='localhost')\n",
    "    conn.autocommit = True\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Check if database exists\n",
    "    cur.execute(\"SELECT 1 FROM pg_database WHERE datname = 'nyc_gentrification'\")\n",
    "    exists = cur.fetchone()\n",
    "    \n",
    "    if not exists:\n",
    "        cur.execute('CREATE DATABASE nyc_gentrification')\n",
    "        print(\"Database 'nyc_gentrification' created\")\n",
    "    else:\n",
    "        print(\"Database 'nyc_gentrification' already exists\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    # If that fails, try connecting without specifying a database\n",
    "    try:\n",
    "        conn = psycopg2.connect(user=username, host='localhost')\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        cur.execute(\"SELECT 1 FROM pg_database WHERE datname = 'nyc_gentrification'\")\n",
    "        exists = cur.fetchone()\n",
    "        \n",
    "        if not exists:\n",
    "            cur.execute('CREATE DATABASE nyc_gentrification')\n",
    "            print(\"Database 'nyc_gentrification' created\")\n",
    "        else:\n",
    "            print(\"Database 'nyc_gentrification' already exists\")\n",
    "        \n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e2:\n",
    "        print(f\"Still failing: {e2}\")\n",
    "        print(f\"\\nYour username is: {username}\")\n",
    "        print(\"Try running this in terminal: psql postgres\")\n",
    "\n",
    "# Continue with rest of setup...\n",
    "print(f\"\\nConnecting as user: {username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235cc51-f278-419a-94c2-cc527666e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Connection parameters\n",
    "username = 'michaelcarter'\n",
    "DB_PARAMS = {\n",
    "    'dbname': 'nyc_gentrification',\n",
    "    'user': username,\n",
    "    'password': '',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "print(\"Creating tables...\")\n",
    "\n",
    "# ACS demographics table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS acs_demographics (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    geoid VARCHAR(6) NOT NULL,\n",
    "    borough VARCHAR(50),\n",
    "    year INTEGER NOT NULL,\n",
    "    median_rent REAL,\n",
    "    median_income REAL,\n",
    "    total_pop INTEGER,\n",
    "    white_non_hisp INTEGER,\n",
    "    total_housing_units INTEGER,\n",
    "    vacant_housing_units INTEGER,\n",
    "    UNIQUE(geoid, year)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Permits table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS permits (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    geoid VARCHAR(6) NOT NULL,\n",
    "    year INTEGER NOT NULL,\n",
    "    total_permits INTEGER,\n",
    "    major_alterations INTEGER,\n",
    "    minor_alterations INTEGER,\n",
    "    new_buildings INTEGER,\n",
    "    UNIQUE(geoid, year)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"✓ Tables created\")\n",
    "\n",
    "# Load ACS data\n",
    "print(\"\\nLoading ACS data...\")\n",
    "acs_df = pd.read_csv('nyc_acs_data_2009_2023.csv')\n",
    "acs_df['geoid'] = acs_df['geoid'].astype(str).str.zfill(6)\n",
    "\n",
    "for idx, row in acs_df.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO acs_demographics (geoid, borough, year, median_rent, median_income, \n",
    "                                       total_pop, white_non_hisp, total_housing_units, \n",
    "                                       vacant_housing_units)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (geoid, year) DO NOTHING\n",
    "    \"\"\", (row['geoid'], row['borough'], int(row['year']), float(row['median_rent']), \n",
    "          float(row['median_income']), int(row['total_pop']), int(row['white_non_hisp']),\n",
    "          int(row['total_housing_units']), int(row['vacant_housing_units'])))\n",
    "    \n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"  Loaded {idx} ACS records...\")\n",
    "\n",
    "conn.commit()\n",
    "print(f\"✓ Loaded {len(acs_df)} ACS records\")\n",
    "\n",
    "# Load permits data\n",
    "print(\"\\nLoading permits data...\")\n",
    "permits_df = pd.read_csv('nyc_permits_geocoded.csv')\n",
    "permits_df['geoid'] = permits_df['geoid'].astype(str).str.zfill(6)\n",
    "\n",
    "for idx, row in permits_df.iterrows():\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO permits (geoid, year, total_permits, major_alterations, \n",
    "                            minor_alterations, new_buildings)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (geoid, year) DO NOTHING\n",
    "    \"\"\", (row['geoid'], int(row['year']), int(row['total_permits']), \n",
    "          int(row['major_alterations']), int(row['minor_alterations']), \n",
    "          int(row['new_buildings'])))\n",
    "    \n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"  Loaded {idx} permit records...\")\n",
    "\n",
    "conn.commit()\n",
    "print(f\"✓ Loaded {len(permits_df)} permit records\")\n",
    "\n",
    "# Verify the data\n",
    "print(\"\\n=== Verification ===\")\n",
    "cur.execute(\"SELECT COUNT(*) FROM acs_demographics\")\n",
    "print(f\"ACS records in database: {cur.fetchone()[0]}\")\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM permits\")\n",
    "print(f\"Permit records in database: {cur.fetchone()[0]}\")\n",
    "\n",
    "# Test a join query\n",
    "print(\"\\n=== Sample Query ===\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT a.geoid, a.year, a.borough, a.median_rent, a.median_income, \n",
    "           COALESCE(p.total_permits, 0) as total_permits\n",
    "    FROM acs_demographics a\n",
    "    LEFT JOIN permits p ON a.geoid = p.geoid AND a.year = p.year\n",
    "    ORDER BY a.year, a.geoid\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"geoid | year | borough | rent | income | permits\")\n",
    "print(\"-\" * 60)\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]} | {row[1]} | {row[2]:12s} | ${row[3]:5.0f} | ${row[4]:6.0f} | {row[5]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"\\n✓ Database setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9604a-c86c-49ca-a737-23315051b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect\n",
    "conn = psycopg2.connect(\n",
    "    dbname='nyc_gentrification',\n",
    "    user='michaelcarter',\n",
    "    password='',\n",
    "    host='localhost'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Check what columns are actually in the tables\n",
    "print(\"=== ACS Demographics Table Schema ===\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'acs_demographics'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"  {row[0]:25s} {row[1]}\")\n",
    "\n",
    "print(\"\\n=== Permits Table Schema ===\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'permits'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"  {row[0]:25s} {row[1]}\")\n",
    "\n",
    "# Query with ALL columns\n",
    "print(\"\\n=== Full Data Sample ===\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        a.geoid, \n",
    "        a.year, \n",
    "        a.borough, \n",
    "        a.median_rent, \n",
    "        a.median_income,\n",
    "        a.total_pop,\n",
    "        a.white_non_hisp,\n",
    "        a.total_housing_units,\n",
    "        a.vacant_housing_units,\n",
    "        COALESCE(p.total_permits, 0) as total_permits,\n",
    "        COALESCE(p.major_alterations, 0) as major_alterations,\n",
    "        COALESCE(p.minor_alterations, 0) as minor_alterations,\n",
    "        COALESCE(p.new_buildings, 0) as new_buildings\n",
    "    FROM acs_demographics a\n",
    "    LEFT JOIN permits p ON a.geoid = p.geoid AND a.year = p.year\n",
    "    ORDER BY a.year, a.geoid\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nSample with all variables:\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"\"\"\n",
    "Tract: {row[0]} | Year: {row[1]} | Borough: {row[2]}\n",
    "  Median rent: ${row[3]:.0f}\n",
    "  Median income: ${row[4]:.0f}\n",
    "  Total population: {row[5]:,}\n",
    "  White non-Hispanic: {row[6]:,}\n",
    "  Total housing units: {row[7]:,}\n",
    "  Vacant units: {row[8]:,}\n",
    "  Total permits: {row[9]}\n",
    "  Major alterations: {row[10]}\n",
    "  Minor alterations: {row[11]}\n",
    "  New buildings: {row[12]}\n",
    "    \"\"\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a78c8f-aca3-4c64-95fb-7d14ad56ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Connect\n",
    "conn = psycopg2.connect(\n",
    "    dbname='nyc_gentrification',\n",
    "    user='michaelcarter',\n",
    "    password='',\n",
    "    host='localhost'\n",
    ")\n",
    "\n",
    "# Query the data - get all records, not just 10\n",
    "query = \"\"\"\n",
    "    SELECT total_pop, total_housing_units\n",
    "    FROM acs_demographics\n",
    "    WHERE total_pop IS NOT NULL \n",
    "      AND total_housing_units IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Load into pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Number of records: {len(df)}\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = df['total_pop'].corr(df['total_housing_units'])\n",
    "print(f\"\\nCorrelation coefficient: {correlation:.4f}\")\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['total_housing_units'], df['total_pop'], alpha=0.5, s=10)\n",
    "plt.xlabel('Total Housing Units')\n",
    "plt.ylabel('Total Population')\n",
    "plt.title(f'Population vs Housing Units\\nCorrelation: {correlation:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['total_housing_units'], df['total_pop'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['total_housing_units'], p(df['total_housing_units']), \n",
    "         \"r--\", alpha=0.8, linewidth=2, label='Trend line')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('population_vs_housing.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as 'population_vs_housing.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5720cf-7ac6-42e9-b9ba-f68d6e836849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Connect\n",
    "conn = psycopg2.connect(\n",
    "    dbname='nyc_gentrification',\n",
    "    user='michaelcarter',\n",
    "    password='',\n",
    "    host='localhost'\n",
    ")\n",
    "\n",
    "# Query the data - get all records, not just 10\n",
    "query = \"\"\"\n",
    "    SELECT total_pop, total_housing_units, geoid \n",
    "    FROM acs_demographics\n",
    "    WHERE total_pop IS NOT NULL \n",
    "      AND total_housing_units IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Load into pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df[df.total_housing_units > 8000]\n",
    "#manyUnits = df.filter(total_housing_units > 8000)\n",
    "#manyUnits.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18168d84-6a2f-4190-9b46-b0e392d5c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Connect\n",
    "conn = psycopg2.connect(\n",
    "    dbname='nyc_gentrification',\n",
    "    user='michaelcarter',\n",
    "    password='',\n",
    "    host='localhost'\n",
    ")\n",
    "\n",
    "# Query the data - get all records, not just 10\n",
    "query = \"\"\"\n",
    "    SELECT year, total_pop, total_housing_units, geoid, borough \n",
    "    FROM acs_demographics\n",
    "    WHERE total_pop IS NOT NULL \n",
    "      AND total_housing_units IS NOT NULL\n",
    "      AND geoid IN ('046201', '004401', '12600', '015400')\n",
    "    ORDER BY geoid, year\n",
    "\"\"\"\n",
    "# Load into pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
